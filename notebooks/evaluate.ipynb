{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to reproduce the figures generated in the paper with already trained models. Running this notebook will require adjusting the paths toward the already trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acousticnn.plate.configs.main_dir import main_dir\n",
    "import wandb, time, os, torch\n",
    "os.chdir(main_dir)\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "from acousticnn.plate.dataset import get_dataloader\n",
    "from acousticnn.plate.train import evaluate, _evaluate, _generate_preds\n",
    "from acousticnn.plate.train_fsm import evaluate as evaluate_fsm\n",
    "from acousticnn.plate.train_fsm import _generate_preds as _generate_preds_fsm\n",
    "from acousticnn.utils.model_utils import get_net\n",
    "from acousticnn.plate.train_fsm import extract_mean_std, get_mean_from_field_solution\n",
    "from acousticnn.utils.argparser import get_args, get_config\n",
    "from acousticnn.utils.plot import plot_loss\n",
    "import matplotlib.pyplot as plt\n",
    "from acousticnn.plate.model import model_factory\n",
    "from matplotlib import rcParams\n",
    "verbose = False\n",
    "base_path = os.path.join(main_dir, \"experiments/vibrating_plates\")\n",
    "experiment_path = os.path.join(main_dir, \"experiments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "max_frequency = 250\n",
    "f = np.arange(1, max_frequency +1)\n",
    "model_cfg = \"query_rn18.yaml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, path=None, fsm=False, verbose=False):\n",
    "    net = get_net(model, conditional=config.conditional, len_conditional=len(config.mean_conditional_param) if config.conditional else None).cuda()\n",
    "    if path is None:\n",
    "        path = f\"{experiment_path}/vibrating_plates/{difficulty}/{model}/checkpoint_best\"\n",
    "    net.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "    if fsm is False:\n",
    "        prediction, output = _generate_preds(args, config, net, dataloader)\n",
    "        results = evaluate(args, config, net, dataloader, report_peak_error=True, epoch=None, report_wasserstein=True, verbose=verbose)\n",
    "    elif fsm is True:\n",
    "        prediction, output, _ = _generate_preds_fsm(args, config, net, dataloader)\n",
    "        results = evaluate_fsm(args, config, net, dataloader, report_peak_error=True, epoch=None, report_wasserstein=True, verbose=verbose)\n",
    "    results.update({\"prediction\": prediction})\n",
    "    a, b, c, rmean = results[\"loss (test/val)\"], results[\"wasserstein\"], results[\"frequency_distance\"], results[\"save_rmean\"]\n",
    "    print(f\"{a:4.2f} & {b:4.2f} & {rmean:4.2f} & {c:3.1f}\")\n",
    "    return results\n",
    "\n",
    "def get_field_prediction(batch, dataloader, net, normalize=True):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "        out_mean, out_std = torch.tensor(out_mean).to(args.device), torch.tensor(out_std).to(args.device)\n",
    "        field_mean, field_std = torch.tensor(field_mean).to(args.device), torch.tensor(field_std).to(args.device)\n",
    "        image, field_solution, output, condition = batch[\"bead_patterns\"], batch[\"z_abs_velocity\"], batch[\"z_vel_mean_sq\"], batch[\"sample_mat\"]\n",
    "        image, field_solution, output, condition = image.to(args.device), field_solution.to(args.device), output.to(args.device), condition.to(args.device)\n",
    "        prediction_field = net(image, condition)\n",
    "        pred_field = prediction_field.clone()\n",
    "        prediction = get_mean_from_field_solution(prediction_field, field_mean, field_std)\n",
    "        if normalize is True:\n",
    "            prediction.sub_(out_mean).div_(out_std)\n",
    "    return prediction.cpu(), pred_field.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from torch.cuda.amp import autocast\n",
    "    import time\n",
    "    cfgs = os.listdir(os.path.join(main_dir, \"configs/model_cfg/\"))\n",
    "    for model_cfg in cfgs:\n",
    "        print(model_cfg)\n",
    "        if model_cfg == \"query_unet_1.yaml\":\n",
    "            continue\n",
    "        args = get_args([\"--config\", \"V5000.yaml\", \"--model_cfg\", model_cfg])\n",
    "\n",
    "        config = get_config(args.config)\n",
    "        net = get_net(model_cfg.split(\".\")[0], conditional=config.conditional).cuda().eval()\n",
    "        batch = torch.ones((32, 1, 81, 121)).cuda().float()\n",
    "        with autocast():  # Enable 16-bit casting\n",
    "            start_time = time.time()\n",
    "            torch.cuda.synchronize()\n",
    "            with torch.no_grad():\n",
    "                for i in range(100):\n",
    "                    net(batch)\n",
    "                    torch.cuda.synchronize()\n",
    "            torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            print(f\"Forward pass took {(end_time - start_time)/ 100:.6f} seconds.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"localnet\" # query_unet\n",
    "difficulty = \"V5000_larger\" # G5000, fsm_V5000\n",
    "fsm = True\n",
    "args = get_args([\"--config\", f\"{difficulty}.yaml\", \"--model_cfg\", model_cfg])\n",
    "config = get_config(args.config)\n",
    "args.batch_size = 6\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"vibrating_plates/transfer/bead_ratio/larger/{model}/checkpoint_best\"), fsm=fsm)\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"vibrating_plates/transfer/bead_ratio/smaller/{model}/checkpoint_best\"), fsm=fsm)\n",
    "\n",
    "difficulty = \"V5000_smaller\" # G5000, fsm_V5000\n",
    "args = get_args([\"--config\", f\"{difficulty}.yaml\", \"--model_cfg\", model_cfg])\n",
    "config = get_config(args.config)\n",
    "args.batch_size = 6\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"vibrating_plates/transfer/bead_ratio/smaller/{model}/checkpoint_best\"), fsm=fsm)\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"vibrating_plates/transfer/bead_ratio/larger/{model}/checkpoint_best\"), fsm=fsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulty = \"G5000\" # G5000, V5000\n",
    "args = get_args([\"--config\", f\"{difficulty}.yaml\", \"--model_cfg\", model_cfg])\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "args.batch_size = 6\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = get_results(\"fno_decoder\", verbose=verbose)\n",
    "results5 = get_results(\"deeponet\", verbose=verbose)\n",
    "results7 = get_results(\"fno_fsm\", verbose=verbose, fsm=True)\n",
    "\n",
    "results2 = get_results(\"grid_rn18\", verbose=verbose)\n",
    "results3 = get_results(\"query_rn18\", verbose=verbose)\n",
    "results1 = get_results(\"vit_implicit\", verbose=verbose)\n",
    "\n",
    "results8 = get_results(\"unet\", verbose=verbose, fsm=True)\n",
    "results6 = get_results(\"localnet\", verbose=verbose, fsm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['axes.labelsize'] = 5\n",
    "rcParams['axes.titlesize'] = 5\n",
    "rcParams['axes.titlesize'] = 5\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "\n",
    "figsize = (6.75/4, 1.35)\n",
    "figsize_large = (6.75/3, 1.35)\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Set2([0, 0.5,1]))\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "save_dir = \"../../plots/results\"\n",
    "from scipy.ndimage import zoom\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mse over freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args([\"--config\", \"G5000.yaml\", \"--model_cfg\", model_cfg])\n",
    "args.batch_size = 6\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "G5000_losses = get_results(\"localnet\", verbose=verbose, fsm=True, path=f\"{experiment_path}/vibrating_plates/G5000/localnet/checkpoint_best\")[\"losses_per_f\"]\n",
    "\n",
    "args = get_args([\"--config\", \"V5000.yaml\", \"--model_cfg\", model_cfg])\n",
    "args.batch_size = 6\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "V5000_losses = get_results(\"localnet\", verbose=verbose, fsm=True, path=f\"{experiment_path}/vibrating_plates/V5000/localnet/checkpoint_best\")[\"losses_per_f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "plot = plot_loss(V5000_losses, f, ax, quantile=0.5)\n",
    "plot = plot_loss(G5000_losses, f, ax, quantile=0.5)\n",
    "\n",
    "legend_labels = [\"V-5000\", \"_\", \"G-5000\", \"_\"]\n",
    "ax.legend(legend_labels, loc='upper left')\n",
    "\n",
    "ax.grid(lw=0.2)\n",
    "ax.set_ylim(0, 0.3)\n",
    "ax.set_yticks(np.arange(0, 0.4, 0.1))\n",
    "sns.despine(ax=ax, offset=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir + \"/mse_over_f.svg\", format='svg', dpi = 600, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Frequency Response Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "batch = next(iter(dataloader))\n",
    "actual_frequency_response, field_solution, image =  batch[\"z_vel_mean_sq\"], batch[\"z_abs_velocity\"], batch[\"bead_patterns\"][:, 0]\n",
    "if not normalize:\n",
    "        out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "        actual_frequency_response = actual_frequency_response * out_std + out_mean\n",
    "net = get_net(\"localnet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/vibrating_plates/{difficulty}/localnet/checkpoint_best\"\n",
    "net.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "prediction, prediction_field = get_field_prediction(batch, dataloader, net, normalize=normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(6.75, 1.2))\n",
    "\n",
    "import seaborn as sns\n",
    "for i, ax in enumerate(axes.transpose()):\n",
    "    ax.imshow(image[i], cmap='gray')\n",
    "    ax.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, f\"example_plates.pdf\"), bbox_inches='tight', transparent=True)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(6.75, 1.2))\n",
    "for i, ax in enumerate(axes.transpose()):\n",
    "    ax.plot(actual_frequency_response[i], lw=0.5, label=\"Reference\", color=\"black\", linestyle='dashed',)\n",
    "    ax.plot(prediction[i], lw=0.5, label=\"Prediction\", color=\"#55a78c\")\n",
    "    ax.set_ylim(-20, 80)\n",
    "    #ax.grid(lw=0.2) \n",
    "    ax.set_xlabel('Frequency', fontsize=5)\n",
    "    ax.set_xticks([0, 100, 200, 300])\n",
    "    ax.set_ylabel('Amplitude', fontsize=5)\n",
    "    if i > 0: # Apply changes to all but the first subplot in the lower row\n",
    "        ax.set_yticklabels([]) # Remove y-axis labels\n",
    "        ax.set_yticks([]) # Remove y-axis ticks to keep the grid visible\n",
    "        sns.despine(ax=ax, offset=5, left=True) # Remove left spine for these plots\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    else:\n",
    "        sns.despine(ax=ax, offset=5) # Apply standard despine for the first subplot\n",
    "    ax.grid(lw=0.2) \n",
    "\n",
    "\n",
    "ax.legend()\n",
    "#plt.tight_layout()\n",
    "\n",
    "#plt.savefig(os.path.join(save_dir, f\"example_predictions.pdf\"), bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "batch = next(iter(dataloader))\n",
    "actual_frequency_response, field_solution, image =  batch[\"z_vel_mean_sq\"], batch[\"z_abs_velocity\"], batch[\"bead_patterns\"][:, 0]\n",
    "f = np.arange(1, max_frequency+1)\n",
    "net = get_net(\"localnet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/vibrating_plates/{difficulty}/localnet/checkpoint_best\"\n",
    "net.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "prediction_localnet, prediction_field = get_field_prediction(batch, dataloader, net, normalize=True)\n",
    "net = get_net(\"unet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/vibrating_plates/{difficulty}/unet/checkpoint_best\"\n",
    "net.load_state_dict(torch.load(path)[\"model_state_dict\"])\n",
    "prediction_unet, _ = get_field_prediction(batch, dataloader, net, normalize=True)\n",
    "\n",
    "label_grid, label_query = \"Grid-UNet\", \"FQO-UNet\"\n",
    "idx, freq = 0, 132 #  and 11 \n",
    "\n",
    "if not normalize:\n",
    "        out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "        prediction_localnet = prediction_localnet.mul(out_std).add_(out_mean)\n",
    "        prediction_unet= prediction_unet.mul(out_std).add_(out_mean)\n",
    "        actual_frequency_response = actual_frequency_response.mul(out_std).add_(out_mean)\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=figsize)\n",
    "ax.plot(f, actual_frequency_response[idx][:max_frequency],  label=\"Reference\", color=\"#909090\", lw=0.5, linestyle='dashed', dashes=[1, 1])\n",
    "ax.plot(f, prediction_unet[idx][:max_frequency], alpha = 0.8,  color=\"#e19c2c\", label=label_grid, lw=0.5)\n",
    "ax.plot(f, prediction_localnet[idx][:max_frequency], alpha = 0.8, color=\"#55a78c\", label=label_query, lw=0.5)\n",
    "ax.scatter(freq, actual_frequency_response[idx][freq], color=\"red\", marker=\"x\", s=4, label='Frequency $\\it{f}$')\n",
    "ax.grid(which=\"major\", lw=0.2), ax.set_xticks([0, 100, 200]), ax.set_yticks([-10, 10, 30, 50, 70])\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir + f\"/prediction_{difficulty}.pdf\", format='pdf', transparent=True, bbox_inches='tight')      \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIELD SOLUTIONS #####\n",
    "field_solution_trans = field_solution * field_std + field_mean\n",
    "field_solution_trans = np.sqrt(np.exp(field_solution_trans))\n",
    "field_solution_trans =  zoom(field_solution_trans[idx][freq], 2, order=3)  \n",
    "prediction_field_trans = prediction_field * field_std + field_mean\n",
    "prediction_field_trans = np.sqrt(np.exp(prediction_field_trans))\n",
    "prediction_field_trans =  zoom(prediction_field_trans[idx][freq], 2, order=3)  \n",
    "vmin = np.min((np.min(prediction_field_trans), np.min(field_solution_trans)))\n",
    "vmax = np.max((np.max(prediction_field_trans), np.max(field_solution_trans)))\n",
    "\n",
    "y, x = np.mgrid[0:field_solution_trans.shape[0], 0:field_solution_trans.shape[1]]\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "\n",
    "fig = plt.contourf(x, y, field_solution_trans, levels=20, vmin=vmin, vmax=vmax, antialiased=True, cmap=plt.cm.gray)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/solution.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "fig = plt.contourf(x, y, prediction_field_trans, levels=20, vmin=vmin, vmax=vmax, antialiased=True, cmap=plt.cm.gray)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/pred_field.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "#### Scale #####\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "\n",
    "fig = plt.contourf(x, y, prediction_field_trans*100, levels=20, vmin=vmin, vmax=vmax*100, antialiased=True, cmap=plt.cm.gray)\n",
    "cbar = plt.colorbar(fig)\n",
    "\n",
    "formatter = ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-2, 2))\n",
    "\n",
    "cbar.set_ticks([0, 1, 2, 2.7])\n",
    "\n",
    "cbar.formatter = formatter\n",
    "cbar.update_ticks()\n",
    "cbar.set_label(r'Velocity $\\times 10^{-2}$ m/s', fontsize=5)\n",
    "cbar.ax.tick_params(labelsize=5)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/colorbar.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(dataloader.dataset.files[\"bead_patterns\"][idx,0], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(save_dir + \"/beading_pattern.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE over data amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"10_percent\", \"25_percent\", \"50_percent\", \"75_percent\"]\n",
    "model = \"query_rn18\"\n",
    "data_vary_path = os.path.join(base_path, \"data_variation/\", model, difficulty)\n",
    "paths = [os.path.join(data_vary_path, exp_path,  \"checkpoint_best\") for exp_path in experiments]\n",
    "paths = paths + [os.path.join(base_path, f\"{difficulty}/{model}/checkpoint_best\")]\n",
    "[print(path) for path in paths]\n",
    "loss_a = []\n",
    "for path in paths:\n",
    "    results = get_results(model, verbose=verbose, path=path, fsm=False)\n",
    "    loss_a.append(results[\"loss (test/val)\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"localnet\"\n",
    "data_vary_path = os.path.join(base_path, \"data_variation/\", model, difficulty)\n",
    "paths = [os.path.join(data_vary_path, exp_path,  \"checkpoint_best\") for exp_path in experiments]\n",
    "paths = paths + [os.path.join(base_path, f\"{difficulty}/{model}/checkpoint_best\")]\n",
    "[print(path) for path in paths]\n",
    "\n",
    "loss_b = []\n",
    "for path in paths:\n",
    "    results = get_results(model, verbose=verbose, path=path, fsm=True)\n",
    "    loss_b.append(results[\"loss (test/val)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse over data amout\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "if difficulty == \"V5000\":\n",
    "    max_samples = 4500 \n",
    "size = np.array([0.1, 0.25, 0.5, 0.75, 1])\n",
    "n_samples = max_samples * size\n",
    "ax.plot(n_samples, loss_a,  'o-', color=\"#b38784\",label=\"FQO-RN18\", lw=0.5, markersize=3)\n",
    "ax.plot(n_samples, loss_b,  'o-', color=\"#b5b564\", label=\"FQO-UNet\", lw=0.5, markersize=3)\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "ax.grid(lw=0.2)\n",
    "\n",
    "ax.set_yticks(np.arange(0.1, 0.90, 0.2))\n",
    "ax.set_ylim(0,0.8)\n",
    "ax.set_xticks(np.arange(0, max_samples*1.30, max_samples/2))\n",
    "sns.despine(ax=ax, offset=5)\n",
    "\n",
    "plt.tight_layout()  # Automatically adjusts margins and spacing\n",
    "\n",
    "plt.savefig(save_dir + f\"/data_variation_{difficulty}.svg\", format='svg', dpi = 600, transparent=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
