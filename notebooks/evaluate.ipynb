{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is designed to reproduce the figures generated in the paper with already trained models. Running this notebook will require adjusting the paths toward the already trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from acousticnn.main_dir import main_dir\n",
    "import wandb, time, os, torch\n",
    "os.chdir(main_dir)\n",
    "import numpy as np\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "from acousticnn.plate.dataset import get_dataloader, HDF5Dataset\n",
    "from acousticnn.plate.train import evaluate, _evaluate, _generate_preds\n",
    "from acousticnn.plate.train_fsm import evaluate as evaluate_fsm\n",
    "from acousticnn.plate.train_fsm import _generate_preds as _generate_preds_fsm\n",
    "from acousticnn.plate.train_fsm import extract_mean_std, get_mean_from_field_solution\n",
    "from acousticnn.utils.model_utils import get_net\n",
    "from acousticnn.utils.argparser import get_args, get_config\n",
    "from acousticnn.utils.plot import plot_loss\n",
    "from acousticnn.model import model_factory\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "verbose = False\n",
    "experiment_path = os.path.join(main_dir, \"experiments/vibrating_plates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "max_frequency = 250\n",
    "f = np.arange(1, max_frequency +1)\n",
    "model_cfg = \"fqo_rn18.yaml\"\n",
    "plt.rcParams['axes.labelsize'] = 5\n",
    "plt.rcParams['axes.titlesize'] = 5\n",
    "plt.rcParams['axes.titlesize'] = 5\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "\n",
    "figsize = (6.75/4, 1.35)\n",
    "figsize_large = (6.75/3, 1.35)\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Set2(np.linspace(0,1,2)))\n",
    "plt.rcParams['text.usetex'] = False\n",
    "save_dir = \"plots/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [\"bead_patterns\", \"z_vel_abs\", \"z_vel_mean_sq\", \"phy_para\", \"frequencies\"]\n",
    "\n",
    "\n",
    "def get_results(model, path=None, fsm=False, verbose=False):\n",
    "    net = get_net(model, conditional=config.conditional, len_conditional=len(config.mean_conditional_param) if config.conditional else None).cuda()\n",
    "\n",
    "    if path is None:\n",
    "        path = os.path.join(experiment_path, dataset, model)\n",
    "        path = os.path.join(path, os.listdir(path)[0], \"checkpoint_best\")\n",
    "\n",
    "    state_dict = torch.load(path)[\"model_state_dict\"]\n",
    "    new_state_dict = {}\n",
    "    for key in state_dict:\n",
    "        new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "        new_state_dict[new_key] = state_dict[key]\n",
    "    net.load_state_dict(new_state_dict)\n",
    "    if fsm is False:\n",
    "        prediction, output = _generate_preds(args, config, net, dataloader)\n",
    "        results = evaluate(args, config, net, dataloader, report_peak_error=True, epoch=None, report_wasserstein=True, verbose=verbose)\n",
    "    elif fsm is True:\n",
    "        prediction, output, _ = _generate_preds_fsm(args, config, net, dataloader)\n",
    "        results = evaluate_fsm(args, config, net, dataloader, report_peak_error=True, epoch=None, report_wasserstein=True, verbose=verbose)\n",
    "    results.update({\"prediction\": prediction})\n",
    "    a, b, c, save_rmean = results[\"loss (test/val)\"], results[\"wasserstein\"], results[\"frequency_distance\"], results[\"save_rmean\"]\n",
    "    print(f\"{a:4.2f} & {b:4.2f} & {save_rmean:3.2f} & {c:3.1f}\")\n",
    "    return results\n",
    "\n",
    "def get_field_prediction(batch, dataloader, net, normalize=True):\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "        out_mean, out_std = out_mean.to(args.device), out_std.to(args.device)\n",
    "        field_mean, field_std = field_mean.to(args.device), field_std.to(args.device)\n",
    "        image, field_solution, vel_mean_sq, condition, frequencies = (batch[field].to(args.device) for field in fields)\n",
    "        prediction_field = net(image, condition, frequencies)\n",
    "        prediction = get_mean_from_field_solution(prediction_field, field_mean, field_std, frequencies)\n",
    "        if normalize is True:\n",
    "            prediction.sub_(out_mean[frequencies]).div_(out_std)\n",
    "    return prediction.cpu(), prediction_field.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    from torch.cuda.amp import autocast\n",
    "    import time\n",
    "\n",
    "    for model_cfg in ['fno_decoder.yaml', 'deeponet.yaml', 'fno_fsm.yaml', 'grid_rn18.yaml', \"fqo_rn18.yaml\", 'fqo_vit.yaml', \\\n",
    "                      'grid_unet.yaml', 'fqo_unet.yaml']:\n",
    "        print(model_cfg)\n",
    "        torch.compiler.reset()\n",
    "        args = get_args([\"--config\", \"cfg/V5000.yaml\", \"--model_cfg\", model_cfg])\n",
    "        autocast_enabled = False\n",
    "        model_config = get_config(args.model_cfg)\n",
    "        net = net = model_factory(**model_config, conditional=False).cuda().eval()\n",
    "        if model_cfg not in ('fno_decoder.yaml', 'fno_fsm.yaml'):\n",
    "            print('compiling')\n",
    "            autocast_enabled = True\n",
    "            torch.set_float32_matmul_precision('high')\n",
    "            net = torch.compile(net)\n",
    "        geometries = torch.ones((16, 1, 81, 121)).cuda().float()\n",
    "        frequencies = torch.ones((16, 300)).cuda().float()\n",
    "        with autocast(autocast_enabled):\n",
    "            with torch.no_grad():\n",
    "                for i in range(10):\n",
    "                    net(geometries, None,  frequencies)\n",
    "        with autocast(autocast_enabled):\n",
    "            torch.cuda.synchronize()\n",
    "            start_time = time.time()\n",
    "            with torch.no_grad():\n",
    "                for i in range(100):\n",
    "                    net(geometries, None,  frequencies)\n",
    "            torch.cuda.synchronize()\n",
    "        end_time = time.time()\n",
    "        print(f\"Forward pass took {(end_time - start_time)/ 100:.6f} seconds.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"fqo_unet\" # fqo_rn18\n",
    "dataset = \"cfg/V5000.yaml\"\n",
    "fsm = True\n",
    "args = get_args([\"--config\", dataset, \"--model_cfg\", model_cfg, '--batch_size', '5', '--filter_dataset', 'larger'])\n",
    "config = get_config(args.config)\n",
    "config.dataset_keys = ['bead_patterns', 'z_vel_mean_sq', 'phy_para', 'frequencies', 'z_vel_abs']\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"transfer/bead_ratio/larger/{model}/checkpoint_best\"), fsm=fsm)\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"transfer/bead_ratio/smaller/{model}/checkpoint_best\"), fsm=fsm)\n",
    "\n",
    "args = get_args([\"--config\", dataset, \"--model_cfg\", model_cfg, '--batch_size', '5', '--filter_dataset', 'smaller'])\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"transfer/bead_ratio/smaller/{model}/checkpoint_best\"), fsm=fsm)\n",
    "_ = get_results(model, path=os.path.join(experiment_path, f\"transfer/bead_ratio/larger/{model}/checkpoint_best\"), fsm=fsm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"V5000\" # \"cfg/G5000.yaml\"\n",
    "args = get_args([\"--config\", f'cfg/{dataset}.yaml', \"--model_cfg\", model_cfg, '--batch_size', '5'])\n",
    "config = get_config(args.config)\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results4 = get_results(\"fno_decoder\", verbose=verbose)\n",
    "results5 = get_results(\"deeponet\", verbose=verbose)\n",
    "results7 = get_results(\"fno_fsm\", verbose=verbose, fsm=True)\n",
    "\n",
    "results2 = get_results(\"grid_rn18\", verbose=verbose)\n",
    "results3 = get_results(\"fqo_rn18\", verbose=verbose)\n",
    "results1 = get_results(\"fqo_vit\", verbose=verbose)\n",
    "\n",
    "results8 = get_results(\"grid_unet\", verbose=verbose, fsm=True)\n",
    "results6 = get_results(\"fqo_unet\", verbose=verbose, fsm=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['axes.labelsize'] = 5\n",
    "rcParams['axes.titlesize'] = 5\n",
    "rcParams['axes.titlesize'] = 5\n",
    "plt.rcParams.update({'font.size': 5})\n",
    "\n",
    "figsize = (6.75/4, 1.35)\n",
    "figsize_large = (6.75/3, 1.35)\n",
    "plt.rcParams[\"axes.prop_cycle\"] = plt.cycler(\"color\", plt.cm.Set2([0, 0.5,1]))\n",
    "plt.rcParams['text.usetex'] = False\n",
    "\n",
    "save_dir = \"plots/results\"\n",
    "from scipy.ndimage import zoom\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE per Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'G5000'\n",
    "args = get_args([\"--config\", \"cfg/G5000.yaml\", \"--model_cfg\", model_cfg, '--batch_size', '5'])\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "G5000_losses = get_results(\"fqo_unet\", verbose=verbose, fsm=True)[\"losses_per_f\"]\n",
    "\n",
    "dataset = 'V5000'\n",
    "args = get_args([\"--config\", \"cfg/V5000.yaml\", \"--model_cfg\", model_cfg, '--batch_size', '5'])\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "V5000_losses = get_results(\"fqo_unet\", verbose=verbose, fsm=True)[\"losses_per_f\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "plot = plot_loss(V5000_losses, f, ax, quantile=0.5)\n",
    "plot = plot_loss(G5000_losses, f, ax, quantile=0.5)\n",
    "\n",
    "legend_labels = [\"V-5000\", \"_\", \"G-5000\", \"_\"]\n",
    "ax.legend(legend_labels, loc='upper left')\n",
    "\n",
    "ax.grid(lw=0.2)\n",
    "ax.set_ylim(0, 0.3)\n",
    "ax.set_yticks(np.arange(0, 0.4, 0.1))\n",
    "sns.despine(ax=ax, offset=5)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir + \"/mse_over_f.svg\", format='svg', dpi = 600, transparent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example Frequency Response Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'V5000'\n",
    "args = get_args([\"--config\", f\"cfg/{dataset}.yaml\", \"--model_cfg\", \"fqo_rn18.yaml\"])\n",
    "config = get_config(args.config)\n",
    "V5000_dataset  = HDF5Dataset(args, config, config.data_paths_test, normalization=True)\n",
    "dataloader = torch.utils.data.DataLoader(V5000_dataset, batch_size=5, shuffle=False, num_workers=0)\n",
    "normalize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dataloader))\n",
    "image, velocity_field, vel_mean_sq, condition, frequencies = (batch[field].to(args.device) for field in fields)\n",
    "net = get_net(\"fqo_unet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/{dataset}/fqo_unet\"\n",
    "path = os.path.join(path, os.listdir(path)[0], \"checkpoint_best\")\n",
    "state_dict = torch.load(path)[\"model_state_dict\"]\n",
    "new_state_dict = {}\n",
    "for key in state_dict:\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "net.load_state_dict(new_state_dict)\n",
    "prediction, prediction_field = get_field_prediction(batch, dataloader, net, normalize=normalize)\n",
    "\n",
    "vel_mean_sq = vel_mean_sq.cpu()\n",
    "velocity_field = velocity_field.cpu()\n",
    "frequencies = frequencies.cpu()\n",
    "image = image.cpu()\n",
    "\n",
    "if not normalize:\n",
    "        out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "        vel_mean_sq = vel_mean_sq * out_std + out_mean[frequencies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 5, figsize=(6.75, 1.2))\n",
    "\n",
    "import seaborn as sns\n",
    "for i, ax in enumerate(axes.transpose()):\n",
    "    ax.imshow(image[i,0], cmap='gray')\n",
    "    ax.axis('off')\n",
    "# plt.savefig(os.path.join(save_dir, f\"example_plates.svg\"), bbox_inches='tight', transparent=True)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 5, figsize=(6.75, 1.2))\n",
    "for i, ax in enumerate(axes.transpose()):\n",
    "    ax.plot(vel_mean_sq[i], lw=0.5, label=\"Reference\", color=\"black\", linestyle='dashed',)\n",
    "    ax.plot(prediction[i], lw=0.5, label=\"Prediction\", color=\"#55a78c\")\n",
    "    ax.set_ylim(-20, 80)\n",
    "    #ax.grid(lw=0.2)\n",
    "    ax.set_xlabel('Frequency', fontsize=5)\n",
    "    ax.set_xticks([0, 100, 200, 300])\n",
    "    ax.set_ylabel('Amplitude', fontsize=5)\n",
    "    if i > 0: # Apply changes to all but the first subplot in the lower row\n",
    "        ax.set_yticklabels([]) # Remove y-axis labels\n",
    "        ax.set_yticks([]) # Remove y-axis ticks to keep the grid visible\n",
    "        sns.despine(ax=ax, offset=5, left=True) # Remove left spine for these plots\n",
    "        ax.set_ylabel(\"\")\n",
    "\n",
    "    else:\n",
    "        sns.despine(ax=ax, offset=5) # Apply standard despine for the first subplot\n",
    "    ax.grid(lw=0.2)\n",
    "\n",
    "\n",
    "ax.legend()\n",
    "#plt.tight_layout()\n",
    "\n",
    "#plt.savefig(os.path.join(save_dir, f\"example_predictions.svg\"), bbox_inches='tight', transparent=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = False\n",
    "f = np.arange(1, max_frequency+1)\n",
    "net = get_net(\"fqo_unet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/{dataset}/fqo_unet\"\n",
    "path = os.path.join(path, os.listdir(path)[0], \"checkpoint_best\")\n",
    "state_dict = torch.load(path)[\"model_state_dict\"]\n",
    "new_state_dict = {}\n",
    "for key in state_dict:\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "net.load_state_dict(new_state_dict)\n",
    "prediction_localnet, prediction_field = get_field_prediction(batch, dataloader, net, normalize=True)\n",
    "\n",
    "\n",
    "net = get_net(\"grid_unet\", conditional=False).cuda()\n",
    "path = f\"{experiment_path}/{dataset}/grid_unet\"\n",
    "path = os.path.join(path, os.listdir(path)[0], \"checkpoint_best\")\n",
    "state_dict = torch.load(path)[\"model_state_dict\"]\n",
    "new_state_dict = {}\n",
    "for key in state_dict:\n",
    "    new_key = key.replace(\"_orig_mod.\", \"\")\n",
    "    new_state_dict[new_key] = state_dict[key]\n",
    "net.load_state_dict(new_state_dict)\n",
    "prediction_unet, _ = get_field_prediction(batch, dataloader, net, normalize=True)\n",
    "frequencies = frequencies.cpu()\n",
    "label_grid, label_query = \"Grid-UNet\", \"FQO-UNet\"\n",
    "idx, freq = 0, 132 #  and 11\n",
    "\n",
    "if not normalize:\n",
    "    out_mean, out_std, field_mean, field_std = extract_mean_std(dataloader.dataset)\n",
    "    prediction_localnet = prediction_localnet.mul(out_std).add_(out_mean[frequencies])\n",
    "    prediction_unet= prediction_unet.mul(out_std).add_(out_mean[frequencies])\n",
    "    #vel_mean_sq = vel_mean_sq.mul(out_std).add_(out_mean[frequencies])\n",
    "\n",
    "fig,ax = plt.subplots(1, 1, figsize=figsize)\n",
    "ax.plot(f, vel_mean_sq[idx][:max_frequency],  label=\"Reference\", color=\"#909090\", lw=0.5, linestyle='dashed', dashes=[1, 1])\n",
    "ax.plot(f, prediction_unet[idx][:max_frequency], alpha = 0.8,  color=\"#e19c2c\", label=label_grid, lw=0.5)\n",
    "ax.plot(f, prediction_localnet[idx][:max_frequency], alpha = 0.8, color=\"#55a78c\", label=label_query, lw=0.5)\n",
    "ax.scatter(freq, vel_mean_sq[idx][freq], color=\"red\", marker=\"x\", s=4, label='Frequency $\\it{f}$')\n",
    "ax.grid(which=\"major\", lw=0.2), ax.set_xticks([0, 100, 200]), ax.set_yticks([-10, 10, 30, 50, 70])\n",
    "ax.set_xlabel('Frequency')\n",
    "ax.set_ylabel('Amplitude')\n",
    "ax.legend(loc=\"lower left\", frameon=False)\n",
    "sns.despine(offset=5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(save_dir + f\"/prediction_{dataset}.svg\", format='svg', transparent=True, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### FIELD SOLUTIONS #####\n",
    "field_solution_trans = velocity_field * field_std + field_mean[frequencies].unsqueeze(-1).unsqueeze(-1)\n",
    "field_solution_trans = np.sqrt(np.exp(field_solution_trans))\n",
    "field_solution_trans =  zoom(field_solution_trans[idx][freq], 2, order=3)\n",
    "prediction_field_trans = prediction_field * field_std + field_mean[frequencies].unsqueeze(-1).unsqueeze(-1)\n",
    "prediction_field_trans = np.sqrt(np.exp(prediction_field_trans))\n",
    "prediction_field_trans =  zoom(prediction_field_trans[idx][freq], 2, order=3)\n",
    "vmin = np.min((np.min(prediction_field_trans), np.min(field_solution_trans)))\n",
    "vmax = np.max((np.max(prediction_field_trans), np.max(field_solution_trans)))\n",
    "\n",
    "y, x = np.mgrid[0:field_solution_trans.shape[0], 0:field_solution_trans.shape[1]]\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "\n",
    "fig = plt.contourf(x, y, field_solution_trans, levels=20, vmin=vmin, vmax=vmax, antialiased=True, cmap=plt.cm.gray)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/solution.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "fig = plt.contourf(x, y, prediction_field_trans, levels=20, vmin=vmin, vmax=vmax, antialiased=True, cmap=plt.cm.gray)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/pred_field.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "#### Scale #####\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize_large)\n",
    "\n",
    "fig = plt.contourf(x, y, field_solution_trans*100, levels=20, vmin=vmin, vmax=vmax*100, antialiased=True, cmap=plt.cm.gray)\n",
    "cbar = plt.colorbar(fig)\n",
    "\n",
    "formatter = ScalarFormatter(useMathText=True)\n",
    "formatter.set_powerlimits((-2, 2))\n",
    "\n",
    "cbar.set_ticks([0, 2.7])\n",
    "\n",
    "cbar.formatter = formatter\n",
    "cbar.update_ticks()\n",
    "cbar.set_label(r'Velocity $\\times 10^{-2}$ m/s', fontsize=5)\n",
    "cbar.ax.tick_params(labelsize=5)\n",
    "\n",
    "for c in fig.collections:\n",
    "    c.set_edgecolor(\"face\")\n",
    "plt.tight_layout()\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(save_dir + \"/colorbar.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(dataloader.dataset.files[\"bead_patterns\"][idx,0], cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.savefig(save_dir + \"/beading_pattern.svg\", transparent=True, bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSE over data amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = [\"10_percent\", \"25_percent\", \"50_percent\", \"75_percent\"]\n",
    "model = \"fqo_rn18\"\n",
    "dataset = \"V5000\"\n",
    "\n",
    "args = get_args([\"--config\", \"cfg/V5000.yaml\", \"--model_cfg\", model_cfg, '--batch_size', '2'])\n",
    "config = get_config(args.config)\n",
    "config.max_frequency = max_frequency\n",
    "dataloader = get_dataloader(args, config, logger=None)[2]\n",
    "\n",
    "data_vary_path = os.path.join(experiment_path, \"data_variation/\", model, dataset)\n",
    "paths = [os.path.join(data_vary_path, exp_path) for exp_path in experiments]\n",
    "paths = paths + [os.path.join(experiment_path, f\"{dataset}/{model}\")]\n",
    "paths = [os.path.join(path, os.listdir(path)[0], 'checkpoint_best') for path in paths]\n",
    "\n",
    "[print(path) for path in paths]\n",
    "loss_a = []\n",
    "for path in paths:\n",
    "    results = get_results(model, verbose=verbose, path=path, fsm=False)\n",
    "    loss_a.append(results[\"loss (test/val)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"fqo_unet\"\n",
    "\n",
    "data_vary_path = os.path.join(experiment_path, \"data_variation/\", model, dataset)\n",
    "paths = [os.path.join(data_vary_path, exp_path) for exp_path in experiments]\n",
    "paths = paths + [os.path.join(experiment_path, f\"{dataset}/{model}\")]\n",
    "paths = [os.path.join(path, os.listdir(path)[0], 'checkpoint_best') for path in paths]\n",
    "\n",
    "[print(path) for path in paths]\n",
    "\n",
    "loss_b = []\n",
    "for path in paths:\n",
    "    results = get_results(model, verbose=verbose, path=path, fsm=True)\n",
    "    loss_b.append(results[\"loss (test/val)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmse over data amout\n",
    "fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "max_samples = 4500\n",
    "size = np.array([0.1, 0.25, 0.5, 0.75, 1])\n",
    "n_samples = max_samples * size\n",
    "ax.plot(n_samples, loss_a,  'o-', color=\"#b38784\",label=\"FQO-RN18\", lw=0.5, markersize=3)\n",
    "ax.plot(n_samples, loss_b,  'o-', color=\"#b5b564\", label=\"FQO-UNet\", lw=0.5, markersize=3)\n",
    "plt.xlabel('Number of samples')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "ax.grid(lw=0.2)\n",
    "\n",
    "ax.set_yticks(np.arange(0.1, 0.90, 0.2))\n",
    "ax.set_ylim(0,0.8)\n",
    "ax.set_xticks(np.arange(0, max_samples*1.30, max_samples/2))\n",
    "sns.despine(ax=ax, offset=5)\n",
    "\n",
    "plt.tight_layout()  # Automatically adjusts margins and spacing\n",
    "\n",
    "plt.savefig(save_dir + f\"/data_variation_{dataset}.svg\", format='svg', dpi = 600, transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
